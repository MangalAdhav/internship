#Q)1 Write a python program to display all the header tags from wikipedia.org and make data frame.

from bs4 import BeautifulSoup
import requests
page=requests.get("https://en.wikipedia.org/wiki/Main_Page")
page
soup=BeautifulSoup(page.content)
soup
header_tags=soup.find_all('span',class_='mw-headline')
header_tags
import pandas as pd
df= pd.DataFrame({'header':header_tags})
df


# 2) Write a python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)
#from https://presidentofindia.nic.in/former-presidents.htm and make data frame.
import pandas as pd
from bs4 import BeautifulSoup
import requests
r=requests.get("https://presidentofindia.nic.in/former-presidents")
soup = BeautifulSoup(r.text.replace('\n',' '), "html.parser")
#soup = BeautifulSoup(page.content, "html.parser")
#soup = BeautifulSoup(response.content, "html.parser")
#soup
name = []
for i in soup.find_all('div', class_ ="desc-sec"):
    name.append(i.text)
    
name


df=pd.DataFrame({'Name of President and term of office':name})
df

df1 = pd.DataFrame({'Name of President': name,
                     'Term of Office': ['25th July, 2017 - 25th July 2022','25th July 2012 - 25th July 2017','25th July 2007 - 25th July 2012','July 2002 - 25th July 2007',' 25 July, 1997 - 25 July 2002','25 July, 1992 - 25 July, 1997','25 July, 1987 - 25 July, 1992','25 July, 1982 - 25 July, 1987',' 25 July, 1977 - 25 July, 1982','24 August, 1974 - 11 February, 1977','24 August, 1969 - 24 August, 1974',' 13 May, 1967 - 03 May, 1969','13 May, 1962 - 13 May , 1967','26 January, 1950 - 13 May, 1962']})
df1



#3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame
#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.
#b) Top 10 ODI Batsmen along with the records of their team andrating.
#c) Top 10 ODI bowlers along with the records of their team andrating.

import pandas as pd
from bs4 import BeautifulSoup
import requests

page= requests.get ('https://www.icc-cricket.com/rankings/team-rankings/mens/odi')
page

soup=BeautifulSoup(page.content)
soup

country=soup.find('span',class_='si-fname.si-text') #[class="si-fname si-text"]
country.text

country=[]
for i in soup.find_all('span',class_='si-fname.si-text'):
    country.append(i.text)
    country
    
match=soup.find('div', class_="si-table-data si-matches")
match.text

match=[]
for i in soup.find_all('div', class_="si-table-data si-matches"):
    match.append(i.text)
    match
    
points=soup.find('div',class_="si-table-data si-pts")
points.text

point=[]
for i in soup.find_all('div',class_="si-table-data si-pts"):
    points.append(i.text)
    point
    
rating=soup.find('div',class_="si-table-data si-rating")
rating.text

rating=[]
for i in soup.find_all('div',class_="si-table-data si-rating"):
    rating.append(i.text)
    rating
    
df=pd.DataFrame({"country_name":country,"matches":match,"points":points,"rating":rating})
df


#### no attribute### no output




#4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame
#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.
#b) Top 10 women’s ODI Batting players along with the records of their team and rating.
#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.

import pandas as pd
from bs4 import BeautifulSoup
import requests
page=requests.get('https://www.icc-cricket.com/rankings/team-rankings/womens/odi')
page
soup=BeautifulSoup(page.content,"html.parser")
soup

country=soup.find('span',class_="si-fname si-text")
country.text

country=[]
for i in soup.find_all('span',class_="si-fname si-text"):
    country.append(i.text)
    country
    
match=soup.find('div', class_="si-table-data si-matches")
match.text

match=[]
for i in soup.find_all('div', class_="si-table-data si-matches"):
    match.append(i.text)
    match
    
points=soup.find('div',class_="si-table-data si-pts")
points.text

point=[]
for i in soup.find_all('div',class_="si-table-data si-pts"):
    points.append(i.text)
    point
    
rating=soup.find('div',class_="si-table-data si-rating")
rating.text

rating=[]
for i in soup.find_all('div',class_="si-table-data si-rating"):
    rating.append(i.text)
    rating
    
df=pd.DataFrame({"country_name":country,"matches":match,"points":points,"rating":rating})
df

###no attribute
    

#5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and
# make data frame. i) Headline ii) Time iii) News Link

import pandas as pd
from bs4 import BeautifulSoup
import requests

page= requests.get ('https://www.cnbc.com/world/?region=world')
page

soup=BeautifulSoup(page.content, "html.parser")
soup

headlines=soup.find('a',class_= "LatestNews-headline")
headlines.text

headlines=[]
for i in soup.find_all('a',class_= "LatestNews-headline"):
    headlines.append(i.text)
headlines

time=soup.find('time', class_="LatestNews-timestamp")
time.text

time=[]

for i in soup.find_all('time', class_="LatestNews-timestamp"):
    time.append(i.text)
    time

    #link=soup.find('a',class_="LatestNews-headline")
    #link=[]
#for i in soup.find_all('a',class_="LatestNews-headline"):
    #print(type(i)," ",i)
    #link.append(i.text)
    #link
########## I have tried url but it is not getting fit in dataframe##############################
    
    
    
df=pd.DataFrame({'headlines':headlines,'time':time})

df

#6) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.
#https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame.
#i) Paper Title ii) Authors iii) Published Date iv) Paper URL

import pandas as pd
from bs4 import BeautifulSoup
import requests

page= requests.get ('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')
page

soup=BeautifulSoup(page.content, "html.parser")
soup


Title=[]
for i in soup.find_all('h2',class_="sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg"):
    Title.append(i.text)
    Title

    
Author=[]
for i in soup.find_all('span', class_="sc-1w3fpd7-0 dnCnAO"):#[class="sc-1w3fpd7-0 dnCnAO"]
    Author.append(i.text)
    Author
    

Date=[]
for i in soup.find_all('span',class_="sc-1thf9ly-2 dvggWt"):#class="sc-1thf9ly-2 dvggWt"
    Date.append(i.text)
    Date   

   #paper_URL=soup.find('div',class_="sc-1fdbg4d-0 GaNmj")
   #paper_URL.text

#Paper_URL =[]
#for i in soup.find_all('div',class_="sc-1fdbg4d-0 GaNmj"):
    #paper_URL.append(i.text)
    #paper_URL
    
#######I have tried this paperlink code, it is giving correct output but not getting fit into dataframe.####### 
 
df1=pd.DataFrame({'Title':Title,'Author_name':Author,'Date':Date})
df1
    








#7) Write a python program to scrape mentioned details from dineout.co.inand make data frame.
#i) Restaurant name, ii) Cuisine iii) Location iv) Ratings v) Image URL

from bs4 import BeautifulSoup
import requests
page= requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')
page
soup=BeautifulSoup(page.content, "html.parser")
soup
#first_title = soup.find('div', class_="restnt-info cursor")
#first_title.text

titles=[]
for i in soup.find_all('div',class_ ="restnt-info cursor"):
    titles.append(i.text)
    titles

#loc=soup.find ('div', class_ = "restnt-loc ellipsis")
#loc.text

location=[]
for i in soup.find_all('div',class_ ="restnt-loc ellipsis"):
    location.append(i.text)
    location


#price=soup.find('span', class_ = "double-line-ellipsis")
#price.text

price=[]
for i in soup.find_all('span', class_ = "double-line-ellipsis"):
    price.append(i.text)
    price


#image=soup. find ('img',class_ = "no-img")
#image

images=[]
for i in soup.find_all("img",class_="no-img"):
    images.append(i['data-src'])
    images
    
import pandas as pd
df=pd.DataFrame({'title':titles, 'location': location, 'price': price,'images-url': images})
df






