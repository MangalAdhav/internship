{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0007d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "#= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)Rank,B)Name\n",
    "#C)Artist D)upload views E)views\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c16b7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url= \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf8a9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list for scraping the data\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78eb262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]'):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")\n",
    "        \n",
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")\n",
    "        \n",
    "# Scraping Upload_Date of the videos   #\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]'):\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Upload_date.append(\"-\")\n",
    "        \n",
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]'):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3433aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Artist),len(Upload_date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccf2e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DataFrame for scraped data\n",
    "Wikipedia_table = pd.DataFrame({})\n",
    "Wikipedia_table['Name'] = Name\n",
    "Wikipedia_table['Artist'] = Artist\n",
    "Wikipedia_table['Upload_date'] = Upload_date\n",
    "Wikipedia_table['Views (in Billions)'] = Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2aac3f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Roar\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[48]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Dark Horse\"[49]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name  \\\n",
       "0                             \"Baby Shark Dance\"[6]   \n",
       "1                                    \"Despacito\"[9]   \n",
       "2                        \"Johny Johny Yes Papa\"[17]   \n",
       "3                                   \"Bath Song\"[18]   \n",
       "4                                \"Shape of You\"[19]   \n",
       "5                               \"See You Again\"[22]   \n",
       "6                           \"Wheels on the Bus\"[27]   \n",
       "7                 \"Phonics Song with Two Words\"[28]   \n",
       "8                                 \"Uptown Funk\"[29]   \n",
       "9   \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]   \n",
       "10                              \"Gangnam Style\"[31]   \n",
       "11   \"Masha and the Bear ‚Äì Recipe for Disaster\"[36]   \n",
       "12                             \"Dame Tu Cosita\"[37]   \n",
       "13                                     \"Axel F\"[38]   \n",
       "14                                      \"Sugar\"[39]   \n",
       "15                             \"Counting Stars\"[40]   \n",
       "16                        \"Baa Baa Black Sheep\"[41]   \n",
       "17                                       \"Roar\"[42]   \n",
       "18                             \"Lakdi Ki Kathi\"[43]   \n",
       "19           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "20                                      \"Sorry\"[45]   \n",
       "21                          \"Thinking Out Loud\"[46]   \n",
       "22          \"Humpty the train on a fruits ride\"[47]   \n",
       "23                      \"Shree Hanuman Chalisa\"[48]   \n",
       "24                                 \"Dark Horse\"[49]   \n",
       "25                                    \"Perfect\"[50]   \n",
       "26                                 \"Let Her Go\"[51]   \n",
       "27                                      \"Faded\"[52]   \n",
       "28                             \"Girls Like You\"[53]   \n",
       "29                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload_date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                                Psy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "17                                         Katy Perry  September 5, 2013   \n",
       "18                                       Jingle Toons      June 14, 2018   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "24                                         Katy Perry  February 20, 2014   \n",
       "25                                         Ed Sheeran   November 9, 2017   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "   Views (in Billions)  \n",
       "0                14.09  \n",
       "1                 8.38  \n",
       "2                 6.87  \n",
       "3                 6.62  \n",
       "4                 6.20  \n",
       "5                 6.17  \n",
       "6                 5.88  \n",
       "7                 5.70  \n",
       "8                 5.15  \n",
       "9                 5.07  \n",
       "10                5.05  \n",
       "11                4.58  \n",
       "12                4.55  \n",
       "13                4.34  \n",
       "14                4.00  \n",
       "15                3.97  \n",
       "16                3.96  \n",
       "17                3.96  \n",
       "18                3.91  \n",
       "19                3.85  \n",
       "20                3.77  \n",
       "21                3.73  \n",
       "22                3.73  \n",
       "23                3.69  \n",
       "24                3.67  \n",
       "25                3.67  \n",
       "26                3.61  \n",
       "27                3.59  \n",
       "28                3.56  \n",
       "29                3.55  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikipedia_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5419b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f36102b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Scrape the details team India‚Äôs international fixtures from bcci.tv.\n",
    "#Url = https://www.bcci.tv/. \n",
    "#You need to find following details:\n",
    "#A) Series B) Place C) Date D) Time \n",
    "\n",
    "#Note: - From bcci.tv home page you have reach to the international fixture page through code. \n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b5735d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url= \"https://www.bcci.tv/.\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f57eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_fixture=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "button_fixture.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdaa9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating empty lists for scraping the data\n",
    "\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append(\"-\")\n",
    "\n",
    "try:     \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append(\"-\")\n",
    "    \n",
    "try:        \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "        Date.append(i.text.replace('\\n',' '))\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "        Time.append(i.text.replace('\\n',' '))\n",
    "except NoSuchElementException:\n",
    "    Time.append(\"-\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd8cd0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6 6 6\n"
     ]
    }
   ],
   "source": [
    "print(len(Series),\n",
    "len(Place),\n",
    "len(Date),\n",
    "len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3451d4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENGLAND TOUR OF INDIA 2023-24',\n",
       " 'INDIA TOUR OF ZIMBABWE 2024',\n",
       " 'INDIA TOUR OF ZIMBABWE 2024',\n",
       " 'INDIA TOUR OF ZIMBABWE 2024',\n",
       " 'INDIA TOUR OF ZIMBABWE 2024',\n",
       " 'INDIA TOUR OF ZIMBABWE 2024']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b53f29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Series  \\\n",
       "0  ENGLAND TOUR OF INDIA 2023-24   \n",
       "1    INDIA TOUR OF ZIMBABWE 2024   \n",
       "2    INDIA TOUR OF ZIMBABWE 2024   \n",
       "3    INDIA TOUR OF ZIMBABWE 2024   \n",
       "4    INDIA TOUR OF ZIMBABWE 2024   \n",
       "5    INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0  Himachal Pradesh Cricket Association Stadium, ...  7 MARCH, 2024   \n",
       "1                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "2                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "3                         Harare Sports Club, Harare  10 JULY, 2024   \n",
       "4                         Harare Sports Club, Harare  13 JULY, 2024   \n",
       "5                         Harare Sports Club, Harare  14 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  9:30 AM IST  \n",
       "1  8:00 PM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "df=pd.DataFrame({\"Series\": Series, \"Place\": Place,\"Date\": Date,\"Time\": Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7eb3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0d129ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ \n",
    "#You have to find following details: A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices \n",
    "#E) Share(18-19) F) GDP($ billion) \n",
    "#Note: - From statisticstimes home page you have to reach to economy page through code. \n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab9d27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url= \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f84a78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking ad opening economy-->india tab\n",
    "click_economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "\n",
    "click_india=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "click_economy.click()\n",
    "click_india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7fd6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on GDP of indian states\n",
    "click_gdp=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "click_gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed0ded9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1= []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []\n",
    "\n",
    "# scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]'):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "# scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]'):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    \n",
    "# scraping GSDP at current price (21-22)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]'):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")\n",
    "    \n",
    "# scraping GSDP at current price (22-23)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[7]'):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "    \n",
    "# scraping Share (21-22)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]'):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "    \n",
    "# scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]'):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0cf56b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 66 66 66 66 66\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(State),len(GSDP1),len(GSDP2),len(Share),len(GDP_billion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5769e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (21-22)</th>\n",
       "      <th>GSDP at current price (22-23)</th>\n",
       "      <th>Share (21-22)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>1,453,321</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>1,304,678</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>1,326,319</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>-</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>31,669</td>\n",
       "      <td>17,214</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>31,519</td>\n",
       "      <td>16,764</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>17,832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,859</td>\n",
       "      <td>15,495</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,293</td>\n",
       "      <td>15,847</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>9,209</td>\n",
       "      <td>6,558</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price (21-22)  \\\n",
       "0     1                Maharashtra                     3,108,022   \n",
       "1     2                 Tamil Nadu                     2,071,286   \n",
       "2     3              Uttar Pradesh                     1,974,532   \n",
       "3     4                  Karnataka                     1,962,725   \n",
       "4     5                    Gujarat                     1,937,066   \n",
       "..  ...                        ...                           ...   \n",
       "61   29          Arunachal Pradesh                        31,669   \n",
       "62   30                     Sikkim                        31,519   \n",
       "63   31                   Nagaland                        27,859   \n",
       "64   32                    Mizoram                        24,293   \n",
       "65   33  Andaman & Nicobar Islands                         9,209   \n",
       "\n",
       "   GSDP at current price (22-23) Share (21-22) GDP($ billion)  \n",
       "0                              -        13.24%        417.163  \n",
       "1                      1,453,321         8.82%        278.011  \n",
       "2                      1,304,678         8.41%        265.024  \n",
       "3                      1,326,319         8.36%        263.440  \n",
       "4                              -         8.25%        259.996  \n",
       "..                           ...           ...            ...  \n",
       "61                        17,214         0.16%              -  \n",
       "62                        16,764         0.16%         17,832  \n",
       "63                        15,495         0.14%              -  \n",
       "64                        15,847         0.12%              -  \n",
       "65                         6,558         0.05%              -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame from the scraped data\n",
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (21-22)'] = GSDP1\n",
    "GDP['GSDP at current price (22-23)'] = GSDP2\n",
    "GDP['Share (21-22)'] = Share\n",
    "GDP['GDP($ billion)'] = GDP_billion\n",
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b410afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6874565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Scrape the details of trending repositories on Github.com. \n",
    "#Url = https://github.com/ \n",
    "#You have to find the following details: \n",
    "#A) Repository title , B) Repository description, C) Contributors count D) Language used \n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "071948bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url = \"https://github.com/\" \n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea54a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on open source and then trending option\n",
    "open_source=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "open_source.click()\n",
    "trend_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trend_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88d34706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching 1st page of URLs of smartphone\n",
    "urls = []\n",
    "url = driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "456d634b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/layerdiffusion/sd-forge-layerdiffusion',\n",
       " 'https://github.com/naver/dust3r',\n",
       " 'https://github.com/EbookFoundation/free-programming-books',\n",
       " 'https://github.com/cooderl/wewe-rss',\n",
       " 'https://github.com/ReVanced/revanced-manager',\n",
       " 'https://github.com/AUTOMATIC1111/stable-diffusion-webui',\n",
       " 'https://github.com/pydantic/FastUI',\n",
       " 'https://github.com/iptv-org/iptv',\n",
       " 'https://github.com/ente-io/ente',\n",
       " 'https://github.com/vercel/ai',\n",
       " 'https://github.com/bigcode-project/starcoder2',\n",
       " 'https://github.com/adrianhajdin/brainwave',\n",
       " 'https://github.com/microsoft/generative-ai-for-beginners',\n",
       " 'https://github.com/microsoft/Security-101',\n",
       " 'https://github.com/nodejs/nodejs.org',\n",
       " 'https://github.com/Lissy93/web-check',\n",
       " 'https://github.com/jafioti/luminal',\n",
       " 'https://github.com/cloudcommunity/Free-Certifications',\n",
       " 'https://github.com/allenai/OLMo',\n",
       " 'https://github.com/microsoft/AI-For-Beginners',\n",
       " 'https://github.com/alireza0/s-ui',\n",
       " 'https://github.com/argmaxinc/WhisperKit',\n",
       " 'https://github.com/memorysafety/river',\n",
       " 'https://github.com/FuelLabs/fuel-core',\n",
       " 'https://github.com/SerenityOS/serenity']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfc88386",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title = []\n",
    "# scraping Repository title data\n",
    "title = driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "for i in title:\n",
    "    Repository_title.append(i.text)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd1350fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layerdiffusion / sd-forge-layerdiffusion',\n",
       " 'naver / dust3r',\n",
       " 'EbookFoundation / free-programming-books',\n",
       " 'cooderl / wewe-rss',\n",
       " 'ReVanced / revanced-manager',\n",
       " 'AUTOMATIC1111 / stable-diffusion-webui',\n",
       " 'pydantic / FastUI',\n",
       " 'iptv-org / iptv',\n",
       " 'ente-io / ente',\n",
       " 'vercel / ai',\n",
       " 'bigcode-project / starcoder2',\n",
       " 'adrianhajdin / brainwave',\n",
       " 'microsoft / generative-ai-for-beginners',\n",
       " 'microsoft / Security-101',\n",
       " 'nodejs / nodejs.org',\n",
       " 'Lissy93 / web-check',\n",
       " 'jafioti / luminal',\n",
       " 'cloudcommunity / Free-Certifications',\n",
       " 'allenai / OLMo',\n",
       " 'microsoft / AI-For-Beginners',\n",
       " 'alireza0 / s-ui',\n",
       " 'argmaxinc / WhisperKit',\n",
       " 'memorysafety / river',\n",
       " 'FuelLabs / fuel-core',\n",
       " 'SerenityOS / serenity']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repository_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e272c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list\n",
    "\n",
    "Repository_description = []\n",
    "Contributors = []\n",
    "Language_used = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    \n",
    "     #scraping Repository Description data \n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        Repository_description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append('-')\n",
    "     \n",
    "    #scraping contributors   \n",
    "    try:\n",
    "        contri = driver.find_element(By.XPATH,'//span[@class=\"Counter ml-1\"]')\n",
    "        Contributors.append(contri.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "    \n",
    "    #scraping language used\n",
    "    try:\n",
    "        language = driver.find_element(By.XPATH,'//ul[@class=\"list-style-none\"]')\n",
    "        Language_used.append(language.text)\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39199bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(Repository_title),len(Repository_description),len(Contributors),len(Language_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0baa5f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layerdiffusion / sd-forge-layerdiffusion</td>\n",
       "      <td>[WIP] Layer Diffusion for WebUI (via Forge)</td>\n",
       "      <td></td>\n",
       "      <td>Python\\n100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naver / dust3r</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>Python\\n100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>üìö Freely available programming books</td>\n",
       "      <td>2,857</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cooderl / wewe-rss</td>\n",
       "      <td>ü§óÊõ¥‰ºòÈõÖÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ËÆ¢ÈòÖÊñπÂºèÔºåÊîØÊåÅÁßÅÊúâÂåñÈÉ®ÁΩ≤„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑RSSÁîüÊàêÔºàÂü∫‰∫éÂæÆ‰ø°ËØª‰π¶Ôºâ„ÄÇ</td>\n",
       "      <td>2</td>\n",
       "      <td>wewe-rss-server\\nwewe-rss-web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReVanced / revanced-manager</td>\n",
       "      <td>üíä Application to use ReVanced on Android</td>\n",
       "      <td>51</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUTOMATIC1111 / stable-diffusion-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td></td>\n",
       "      <td>Python\\n87.0%\\nJavaScript\\n8.8%\\nCSS\\n2.2%\\nHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pydantic / FastUI</td>\n",
       "      <td>Build better UIs faster.</td>\n",
       "      <td>26</td>\n",
       "      <td>Python\\n51.8%\\nTypeScript\\n45.8%\\nSCSS\\n1.1%\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iptv-org / iptv</td>\n",
       "      <td>Collection of publicly available IPTV channels...</td>\n",
       "      <td>261</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ente-io / ente</td>\n",
       "      <td>Fully open source, End to End Encrypted altern...</td>\n",
       "      <td>34</td>\n",
       "      <td>TypeScript\\n54.6%\\nDart\\n31.3%\\nGo\\n9.9%\\nHTML...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vercel / ai</td>\n",
       "      <td>Build AI-powered applications with React, Svel...</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript\\n99.0%\\nOther\\n1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bigcode-project / starcoder2</td>\n",
       "      <td>Home of StarCoder2!</td>\n",
       "      <td></td>\n",
       "      <td>Python\\n100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adrianhajdin / brainwave</td>\n",
       "      <td>Learn to create modern websites with sleek par...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript\\n97.4%\\nCSS\\n2.0%\\nHTML\\n0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>microsoft / generative-ai-for-beginners</td>\n",
       "      <td>18 Lessons, Get Started Building with Generati...</td>\n",
       "      <td>50</td>\n",
       "      <td>Jupyter Notebook\\n85.0%\\nPython\\n11.2%\\nTypeSc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>microsoft / Security-101</td>\n",
       "      <td>7 Lessons, Kick-start Your Cybersecurity Learn...</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nodejs / nodejs.org</td>\n",
       "      <td>The Node.js¬Æ Website</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript\\n70.6%\\nJavaScript\\n19.1%\\nCSS\\n6.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lissy93 / web-check</td>\n",
       "      <td>üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any ...</td>\n",
       "      <td>1</td>\n",
       "      <td>web-check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jafioti / luminal</td>\n",
       "      <td>Deep learning at the speed of light.</td>\n",
       "      <td></td>\n",
       "      <td>Rust\\n92.3%\\nC++\\n4.6%\\nMetal\\n2.9%\\nOther\\n0.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>69</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>allenai / OLMo</td>\n",
       "      <td>Modeling, training, eval, and inference code f...</td>\n",
       "      <td>1</td>\n",
       "      <td>llm-lumi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>microsoft / AI-For-Beginners</td>\n",
       "      <td>12 Weeks, 24 Lessons, AI for All!</td>\n",
       "      <td></td>\n",
       "      <td>Jupyter Notebook\\n99.8%\\nPython\\n0.1%\\nHTML\\n0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>alireza0 / s-ui</td>\n",
       "      <td>An advanced Web Panel ‚Ä¢ Built for SagerNet/Sin...</td>\n",
       "      <td>1</td>\n",
       "      <td>s-ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>argmaxinc / WhisperKit</td>\n",
       "      <td>Swift native on-device speech recognition with...</td>\n",
       "      <td>6</td>\n",
       "      <td>Swift\\n99.0%\\nMakefile\\n1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>memorysafety / river</td>\n",
       "      <td>This repository is the future home of the Rive...</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FuelLabs / fuel-core</td>\n",
       "      <td>Rust full node implementation of the Fuel v2 p...</td>\n",
       "      <td>9</td>\n",
       "      <td>fuel-core\\nfuel-core-e2e-client\\nfuel-core-debug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SerenityOS / serenity</td>\n",
       "      <td>The Serenity Operating System üêû</td>\n",
       "      <td>1,006</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository Title  \\\n",
       "0   layerdiffusion / sd-forge-layerdiffusion   \n",
       "1                             naver / dust3r   \n",
       "2   EbookFoundation / free-programming-books   \n",
       "3                         cooderl / wewe-rss   \n",
       "4                ReVanced / revanced-manager   \n",
       "5     AUTOMATIC1111 / stable-diffusion-webui   \n",
       "6                          pydantic / FastUI   \n",
       "7                            iptv-org / iptv   \n",
       "8                             ente-io / ente   \n",
       "9                                vercel / ai   \n",
       "10              bigcode-project / starcoder2   \n",
       "11                  adrianhajdin / brainwave   \n",
       "12   microsoft / generative-ai-for-beginners   \n",
       "13                  microsoft / Security-101   \n",
       "14                       nodejs / nodejs.org   \n",
       "15                       Lissy93 / web-check   \n",
       "16                         jafioti / luminal   \n",
       "17      cloudcommunity / Free-Certifications   \n",
       "18                            allenai / OLMo   \n",
       "19              microsoft / AI-For-Beginners   \n",
       "20                           alireza0 / s-ui   \n",
       "21                    argmaxinc / WhisperKit   \n",
       "22                      memorysafety / river   \n",
       "23                      FuelLabs / fuel-core   \n",
       "24                     SerenityOS / serenity   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "0         [WIP] Layer Diffusion for WebUI (via Forge)                      \n",
       "1                                                   -                      \n",
       "2                üìö Freely available programming books              2,857   \n",
       "3          ü§óÊõ¥‰ºòÈõÖÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ËÆ¢ÈòÖÊñπÂºèÔºåÊîØÊåÅÁßÅÊúâÂåñÈÉ®ÁΩ≤„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑RSSÁîüÊàêÔºàÂü∫‰∫éÂæÆ‰ø°ËØª‰π¶Ôºâ„ÄÇ                  2   \n",
       "4            üíä Application to use ReVanced on Android                 51   \n",
       "5                             Stable Diffusion web UI                      \n",
       "6                            Build better UIs faster.                 26   \n",
       "7   Collection of publicly available IPTV channels...                261   \n",
       "8   Fully open source, End to End Encrypted altern...                 34   \n",
       "9   Build AI-powered applications with React, Svel...                      \n",
       "10                                Home of StarCoder2!                      \n",
       "11  Learn to create modern websites with sleek par...                  -   \n",
       "12  18 Lessons, Get Started Building with Generati...                 50   \n",
       "13  7 Lessons, Kick-start Your Cybersecurity Learn...                      \n",
       "14                               The Node.js¬Æ Website                      \n",
       "15  üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any ...                  1   \n",
       "16               Deep learning at the speed of light.                      \n",
       "17   A curated list of free courses & certifications.                 69   \n",
       "18  Modeling, training, eval, and inference code f...                  1   \n",
       "19                  12 Weeks, 24 Lessons, AI for All!                      \n",
       "20  An advanced Web Panel ‚Ä¢ Built for SagerNet/Sin...                  1   \n",
       "21  Swift native on-device speech recognition with...                  6   \n",
       "22  This repository is the future home of the Rive...                  2   \n",
       "23  Rust full node implementation of the Fuel v2 p...                  9   \n",
       "24                    The Serenity Operating System üêû              1,006   \n",
       "\n",
       "                                        Language Used  \n",
       "0                                      Python\\n100.0%  \n",
       "1                                      Python\\n100.0%  \n",
       "2                                                   -  \n",
       "3                       wewe-rss-server\\nwewe-rss-web  \n",
       "4                                                      \n",
       "5   Python\\n87.0%\\nJavaScript\\n8.8%\\nCSS\\n2.2%\\nHT...  \n",
       "6   Python\\n51.8%\\nTypeScript\\n45.8%\\nSCSS\\n1.1%\\n...  \n",
       "7                                                      \n",
       "8   TypeScript\\n54.6%\\nDart\\n31.3%\\nGo\\n9.9%\\nHTML...  \n",
       "9                      TypeScript\\n99.0%\\nOther\\n1.0%  \n",
       "10                                     Python\\n100.0%  \n",
       "11           JavaScript\\n97.4%\\nCSS\\n2.0%\\nHTML\\n0.6%  \n",
       "12  Jupyter Notebook\\n85.0%\\nPython\\n11.2%\\nTypeSc...  \n",
       "13                                                  -  \n",
       "14  TypeScript\\n70.6%\\nJavaScript\\n19.1%\\nCSS\\n6.0...  \n",
       "15                                          web-check  \n",
       "16   Rust\\n92.3%\\nC++\\n4.6%\\nMetal\\n2.9%\\nOther\\n0.2%  \n",
       "17                                                     \n",
       "18                                           llm-lumi  \n",
       "19  Jupyter Notebook\\n99.8%\\nPython\\n0.1%\\nHTML\\n0...  \n",
       "20                                               s-ui  \n",
       "21                       Swift\\n99.0%\\nMakefile\\n1.0%  \n",
       "22                                                  -  \n",
       "23   fuel-core\\nfuel-core-e2e-client\\nfuel-core-debug  \n",
       "24                                                     "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets dataframe\n",
    "Trending_github = pd.DataFrame({})\n",
    "Trending_github['Repository Title'] = Repository_title\n",
    "Trending_github['Repository Description'] = Repository_description\n",
    "Trending_github['Contributors Count'] = Contributors\n",
    "Trending_github['Language Used'] = Language_used\n",
    "Trending_github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "052ea1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e07195b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "#following details: \n",
    "#A) Song name, B) Artist name,C) Last week rank D) Peak rank E) Weeks on board \n",
    " \n",
    "#Note: - From the home page you have to click on the charts option then hot 100-page link through code. \n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3e648cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url = \"https:/www.billboard.com/\" \n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffa6e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_btn=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4169dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_chart_btn=driver.find_element(By.XPATH,'//div[@class=\"lrv-u-flex lrv-u-justify-content-center\"]')\n",
    "view_chart_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e231ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//li//h3'):\n",
    "    Song.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d792e5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Texas Hold 'Em\",\n",
       " 'Lovin On Me',\n",
       " 'Lose Control',\n",
       " 'Carnival',\n",
       " 'Beautiful Things',\n",
       " 'Snooze',\n",
       " 'Cruel Summer',\n",
       " 'Greedy',\n",
       " 'I Remember Everything',\n",
       " 'Agora Hills',\n",
       " 'Yes, And?',\n",
       " 'Stick Season',\n",
       " 'Fast Car',\n",
       " 'Water',\n",
       " 'Last Night',\n",
       " 'Redrum',\n",
       " \"Thinkin' Bout Me\",\n",
       " \"Is It Over Now? (Taylor's Version) [From The Vault]\",\n",
       " 'Pretty Little Poison',\n",
       " 'Flowers',\n",
       " 'Paint The Town Red',\n",
       " 'Houdini',\n",
       " 'Made For Me',\n",
       " 'Never Lose Me',\n",
       " 'La Diabla',\n",
       " 'Where The Wild Things Are',\n",
       " 'Training Season',\n",
       " 'The Painter',\n",
       " 'Feather',\n",
       " 'What Was I Made For?',\n",
       " 'Rich Baby Daddy',\n",
       " 'Whatever She Wants',\n",
       " 'Truck Bed',\n",
       " 'Selfish',\n",
       " 'Everybody',\n",
       " 'Vampire',\n",
       " 'Wild Ones',\n",
       " 'On My Mama',\n",
       " 'Praise Jah In The Moonlight',\n",
       " 'Save Me',\n",
       " 'Exes',\n",
       " 'Breathe',\n",
       " 'Dance The Night',\n",
       " 'Need A Favor',\n",
       " 'Surround Sound',\n",
       " 'World On Fire',\n",
       " 'Yeah!',\n",
       " 'Burn It Down',\n",
       " 'Good Good',\n",
       " 'La Victima',\n",
       " 'End Of Beginning',\n",
       " 'Get In With Me',\n",
       " 'Burn',\n",
       " 'Man Made A Bar',\n",
       " '16 Carriages',\n",
       " 'First Person Shooter',\n",
       " 'Fuk Sumn',\n",
       " 'One Of The Girls',\n",
       " 'Back To Me',\n",
       " 'One Call',\n",
       " 'Contigo',\n",
       " '23',\n",
       " 'Murder On The Dancefloor',\n",
       " 'You Broke My Heart',\n",
       " 'Think U The Shit (Fart)',\n",
       " 'FTCU',\n",
       " 'FE!N',\n",
       " 'Hiss',\n",
       " 'I Can Feel It',\n",
       " 'Bandit',\n",
       " 'Spin You Around (1/24)',\n",
       " 'Soak City',\n",
       " 'Forever',\n",
       " \"Mamaw's House\",\n",
       " 'Act II: Date @ 8',\n",
       " 'Igual Que Un Angel',\n",
       " 'Nee-nah',\n",
       " 'Wildflowers And Wild Horses',\n",
       " 'Bellakeo',\n",
       " 'Harley Quinn',\n",
       " 'Standing Next To You',\n",
       " 'Bittersweet',\n",
       " 'IDGAF',\n",
       " 'Home',\n",
       " 'Vultures',\n",
       " 'Yeah Glo!',\n",
       " 'Coal',\n",
       " 'Mmhmm',\n",
       " 'Psycho CEO',\n",
       " 'Perro Negro',\n",
       " 'Sensational',\n",
       " 'Oklahoma Smokeshow',\n",
       " 'Tu Name',\n",
       " 'Do It',\n",
       " 'Worth It',\n",
       " 'Talking',\n",
       " 'Monaco',\n",
       " 'Where It Ends',\n",
       " 'Wondering Why',\n",
       " 'Northern Attitude']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db493d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyonce'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j= driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/span')\n",
    "j.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3bc995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Week_on_board=[]\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    Artist_name.append(j.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "        Artist_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist_name.append(\"-\")  \n",
    "try:   \n",
    "    for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"][1]'):\n",
    "        Last_week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_week_rank.append(\"-\")  \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"][2]'):\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    peak_rank.append(\"-\")  \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"][2]'):\n",
    "        Week_on_board.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Week_on_board.append(\"-\")  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ce4d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Song), len(Artist_name),len(Last_week_rank),len(Peak_rank),len(Week_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75097ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beyonce',\n",
       " 'Jack Harlow',\n",
       " 'Teddy Swims',\n",
       " '¬•$: Kanye West & Ty Dolla $ign Featuring Rich The Kid & Playboi Carti',\n",
       " 'Benson Boone',\n",
       " 'SZA',\n",
       " 'Taylor Swift',\n",
       " 'Tate McRae',\n",
       " 'Zach Bryan Featuring Kacey Musgraves',\n",
       " 'Doja Cat',\n",
       " 'Ariana Grande',\n",
       " 'Noah Kahan',\n",
       " 'Luke Combs',\n",
       " 'Tyla',\n",
       " 'Morgan Wallen',\n",
       " '21 Savage',\n",
       " 'Morgan Wallen',\n",
       " 'Taylor Swift',\n",
       " 'Warren Zeiders',\n",
       " 'Miley Cyrus',\n",
       " 'Doja Cat',\n",
       " 'Dua Lipa',\n",
       " 'Muni Long',\n",
       " 'Flo Milli',\n",
       " 'Xavi',\n",
       " 'Luke Combs',\n",
       " 'Dua Lipa',\n",
       " 'Cody Johnson',\n",
       " 'Sabrina Carpenter',\n",
       " 'Billie Eilish',\n",
       " 'Drake Featuring Sexyy Red & SZA',\n",
       " 'Bryson Tiller',\n",
       " 'HARDY',\n",
       " 'Justin Timberlake',\n",
       " 'Nicki Minaj Featuring Lil Uzi Vert',\n",
       " 'Olivia Rodrigo',\n",
       " 'Jessie Murph & Jelly Roll',\n",
       " 'Victoria Monet',\n",
       " 'YG Marley',\n",
       " 'Jelly Roll With Lainey Wilson',\n",
       " 'Tate McRae',\n",
       " 'Yeat',\n",
       " 'Dua Lipa',\n",
       " 'Jelly Roll',\n",
       " 'JID Featuring 21 Savage & Baby Tate',\n",
       " 'Nate Smith',\n",
       " 'Usher Featuring Lil Jon & Ludacris',\n",
       " 'Parker McCollum',\n",
       " 'Usher, Summer Walker & 21 Savage',\n",
       " 'Xavi',\n",
       " 'Djo',\n",
       " 'BossMan Dlow',\n",
       " '¬•$: Kanye West & Ty Dolla $ign',\n",
       " 'Morgan Wallen Featuring Eric Church',\n",
       " 'Beyonce',\n",
       " 'Drake Featuring J. Cole',\n",
       " '¬•$: Kanye West & Ty Dolla $ign',\n",
       " 'The Weeknd, Jennie & Lily Rose Depp',\n",
       " '¬•$: Kanye West & Ty Dolla $ign',\n",
       " 'Rich Amiri',\n",
       " 'Karol G & Tiesto',\n",
       " 'Chayce Beckham',\n",
       " 'Sophie Ellis-Bextor',\n",
       " 'Drake',\n",
       " 'Ice Spice',\n",
       " 'Nicki Minaj',\n",
       " 'Travis Scott Featuring Playboi Carti',\n",
       " 'Megan Thee Stallion',\n",
       " 'Kane Brown',\n",
       " 'Don Toliver',\n",
       " 'Morgan Wallen',\n",
       " '310babii',\n",
       " 'Noah Kahan',\n",
       " 'Thomas Rhett Featuring Morgan Wallen',\n",
       " '4Batz',\n",
       " 'Kali Uchis & Peso Pluma',\n",
       " '21 Savage, Travis Scott & Metro Boomin',\n",
       " 'Lainey Wilson',\n",
       " 'Peso Pluma & Anitta',\n",
       " 'Fuerza Regida & Marshmello',\n",
       " 'Jung Kook',\n",
       " 'Gunna',\n",
       " 'Drake Featuring Yeat',\n",
       " 'Good Neighbours',\n",
       " '¬•$: Kanye West & Ty Dolla $ign Featuring Lil Durk & Bump J',\n",
       " 'GloRilla',\n",
       " 'Dylan Gossett',\n",
       " 'BigXthaPlug',\n",
       " 'Yeat',\n",
       " 'Bad Bunny & Feid',\n",
       " 'Chris Brown Featuring Davido & Lojay',\n",
       " 'Zach Bryan',\n",
       " 'Fuerza Regida',\n",
       " '¬•$: Kanye West & Ty Dolla $ign',\n",
       " 'Offset & Don Toliver',\n",
       " '¬•$: Kanye West & Ty Dolla $ign Featuring North West',\n",
       " 'Bad Bunny',\n",
       " 'Bailey Zimmerman',\n",
       " 'The Red Clay Strays',\n",
       " 'Noah Kahan With Hozier']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aea43a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas Hold 'Em</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carnival</td>\n",
       "      <td>¬•$: Kanye West &amp; Ty Dolla $ign Featuring Rich ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Talking</td>\n",
       "      <td>¬•$: Kanye West &amp; Ty Dolla $ign Featuring North...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Where It Ends</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td>-</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wondering Why</td>\n",
       "      <td>The Red Clay Strays</td>\n",
       "      <td>-</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Northern Attitude</td>\n",
       "      <td>Noah Kahan With Hozier</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                                             Artist  \\\n",
       "0      Texas Hold 'Em                                            Beyonce   \n",
       "1         Lovin On Me                                        Jack Harlow   \n",
       "2        Lose Control                                        Teddy Swims   \n",
       "3            Carnival  ¬•$: Kanye West & Ty Dolla $ign Featuring Rich ...   \n",
       "4    Beautiful Things                                       Benson Boone   \n",
       "..                ...                                                ...   \n",
       "95            Talking  ¬•$: Kanye West & Ty Dolla $ign Featuring North...   \n",
       "96             Monaco                                          Bad Bunny   \n",
       "97      Where It Ends                                   Bailey Zimmerman   \n",
       "98      Wondering Why                                The Red Clay Strays   \n",
       "99  Northern Attitude                             Noah Kahan With Hozier   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on board  \n",
       "0               2         1              2  \n",
       "1               1         1             15  \n",
       "2               5         2             28  \n",
       "3               3         3              2  \n",
       "4               4         3              5  \n",
       "..            ...       ...            ...  \n",
       "95             30        30              2  \n",
       "96             97         5             19  \n",
       "97              -        32              8  \n",
       "98              -        71              8  \n",
       "99             75        37             12  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "df_bilboard = pd.DataFrame({})\n",
    "df_bilboard['Name'] = Song\n",
    "df_bilboard['Artist'] = Artist_name\n",
    "df_bilboard['Last Week Rank'] = Last_week_rank\n",
    "df_bilboard['Peak Rank'] = Peak_rank\n",
    "df_bilboard['Weeks on board'] = Week_on_board\n",
    "df_bilboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "19c51963",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc046466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3aa975a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Scrape the details of Highest selling novels.\n",
    "#A) Book name B) Author name C) Volumes sold D) Publisher E) Genre \n",
    "# Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb2e7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\" \n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b677314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "\n",
    "# scraping book names data\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]'):\n",
    "        Book_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book_name.append(\"-\")  \n",
    "\n",
    "    \n",
    "# scraping author names data\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]'):\n",
    "        Author_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author_name.append(\"-\")  \n",
    "\n",
    "\n",
    "# scraping data of volumes sold\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]'):\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volume_sold.append(\"-\")  \n",
    "\n",
    "    \n",
    "# scraping data of publisher names\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]'):\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append(\"-\")  \n",
    "    \n",
    "    \n",
    "# scraping  data of genre\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]'):\n",
    "        Genre.append(i.text)    \n",
    "except NoSuchElementException:\n",
    "    Genre.append(\"-\")  \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d7b63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book_name),len(Author_name),len(Volumes_sold),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7bd65fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35a03b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10b008c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q 7.Scrape the details most watched tv series of all time from imdb.com. \n",
    "#Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "#to find the following details: A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bdf3e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url = \"https://www.imdb.com/list/ls512407256/\" \n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c716120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "# scraped data of Names\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/a'):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "       Name.append(\"-\")  \n",
    "\n",
    "    \n",
    "    \n",
    "# scraped data of Year span\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]'):\n",
    "        Year_span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Year_span.append(\"-\")  \n",
    "\n",
    "    \n",
    "    \n",
    "# scraped data of Genre\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]'):\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Genre.append(\"-\")  \n",
    "\n",
    "    \n",
    "    \n",
    "# scraped data of Run time\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]'):\n",
    "        Run_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Run_time.append(\"-\")  \n",
    "\n",
    "        \n",
    "# scraped data of Ratings\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]'):\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "       Rating.append(\"-\")  \n",
    "    \n",
    "    \n",
    "# scraped data of Votes\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@name=\"nv\"]'):\n",
    "        Votes.append(i.text) \n",
    "except NoSuchElementException:\n",
    "       Votes.append(\"-\")  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2788f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year_span),len(Genre),len(Run_time),len(Ratings),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d1df2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>55 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,262,827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,320,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,072,421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>313,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>273,449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014‚Äì )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>645,918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011‚Äì2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>162,079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016‚Äì2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>114,898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989‚Äì )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>433,138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004‚Äì2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>138,707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name    Year Span                     Genre Run Time  \\\n",
       "0        Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   55 min   \n",
       "1        Stranger Things  (2016‚Äì2025)    Drama, Fantasy, Horror   51 min   \n",
       "2       The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   44 min   \n",
       "3         13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   60 min   \n",
       "4                The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   43 min   \n",
       "..                   ...          ...                       ...      ...   \n",
       "95        True Detective     (2014‚Äì )     Crime, Drama, Mystery   55 min   \n",
       "96             Teen Wolf  (2011‚Äì2017)    Action, Drama, Fantasy   41 min   \n",
       "97                The OA  (2016‚Äì2019)   Drama, Fantasy, Mystery   60 min   \n",
       "98          The Simpsons     (1989‚Äì )         Animation, Comedy   22 min   \n",
       "99  Desperate Housewives  (2004‚Äì2012)    Comedy, Drama, Mystery   45 min   \n",
       "\n",
       "   Ratings      Votes  \n",
       "0      9.2  2,262,827  \n",
       "1      8.7  1,320,679  \n",
       "2      8.1  1,072,421  \n",
       "3      7.5    313,499  \n",
       "4      7.6    273,449  \n",
       "..     ...        ...  \n",
       "95     8.9    645,918  \n",
       "96     7.7    162,079  \n",
       "97     7.8    114,898  \n",
       "98     8.7    433,138  \n",
       "99     7.6    138,707  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "Series = pd.DataFrame({})\n",
    "Series['Name'] = Name\n",
    "Series['Year Span'] = Year_span\n",
    "Series['Genre'] = Genre\n",
    "Series['Run Time'] = Run_time\n",
    "Series['Ratings'] = Ratings\n",
    "Series['Votes'] = Votes\n",
    "Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2cfc923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7574e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2181c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Details of Datasets from UCI machine learning repositories. \n",
    "#Url = https://archive.ics.uci.edu/ You have to find the following details: \n",
    "#A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year\n",
    "\n",
    "#Note: - from the home page you have to go to the Show All Dataset page through code. \n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium .webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "502a93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver and fetching website\n",
    "driver=webdriver.Chrome()\n",
    "url= \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "09f33821",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataset=driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "view_dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d5bed74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching URLs to open the pages\n",
    "urls = []          # empty list\n",
    "for i in range(0,2):      # for loop to scrape 3 pages\n",
    "    page_url = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "    for i in page_url:\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "        next_btn = driver.find_element(By.XPATH,'//button[@class=\"btn-primary btn-sm btn\"][2]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "66e72933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/850/raisin',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/186/wine+quality',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes',\n",
       " 'https://archive.ics.uci.edu/dataset/53/iris',\n",
       " 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset',\n",
       " 'https://archive.ics.uci.edu/dataset/45/heart+disease',\n",
       " 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik',\n",
       " 'https://archive.ics.uci.edu/dataset/2/adult',\n",
       " 'https://archive.ics.uci.edu/dataset/850/raisin',\n",
       " 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic',\n",
       " 'https://archive.ics.uci.edu/dataset/109/wine',\n",
       " 'https://archive.ics.uci.edu/dataset/186/wine+quality',\n",
       " 'https://archive.ics.uci.edu/dataset/34/diabetes']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b187f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "493614b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping  Dataset name\n",
    "    try:\n",
    "        dataset_name = driver.find_element(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[1]/p\")\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "\n",
    "    \n",
    "    \n",
    "    # scraping Task\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p')\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "\n",
    "    \n",
    "    \n",
    "    # scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p')\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "\n",
    "    \n",
    "    \n",
    "    # scraping No of Instances\n",
    "    try:\n",
    "        instances = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p')\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping No of Arrtibutes\n",
    "    try:\n",
    "        attribute = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p')\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping Year\n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/h2')\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9256bf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset_name),len(Data_type),len(Task),len(Attribute_type),len(No_of_instances),len(No_of_attributes),len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "721efabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instance</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>16</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>7</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900</td>\n",
       "      <td>7</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>11</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>16</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>7</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900</td>\n",
       "      <td>7</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>11</td>\n",
       "      <td>Dona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Data Name                 Data Type   \\\n",
       "0                                   Iris                    Tabular   \n",
       "1                       Dry Bean Dataset               Multivariate   \n",
       "2                          Heart Disease               Multivariate   \n",
       "3             Rice (Cammeo and Osmancik)               Multivariate   \n",
       "4                                  Adult               Multivariate   \n",
       "5                                 Raisin               Multivariate   \n",
       "6   Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "7                                   Wine                    Tabular   \n",
       "8                           Wine Quality               Multivariate   \n",
       "9                               Diabetes  Multivariate, Time-Series   \n",
       "10                                  Iris                    Tabular   \n",
       "11                      Dry Bean Dataset               Multivariate   \n",
       "12                         Heart Disease               Multivariate   \n",
       "13            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "14                                 Adult               Multivariate   \n",
       "15                                Raisin               Multivariate   \n",
       "16  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "17                                  Wine                    Tabular   \n",
       "18                          Wine Quality               Multivariate   \n",
       "19                              Diabetes  Multivariate, Time-Series   \n",
       "\n",
       "                         Task              Attribute Type  No of Instance   \\\n",
       "0               Classification                        Real             150   \n",
       "1               Classification               Integer, Real           13611   \n",
       "2               Classification  Categorical, Integer, Real             303   \n",
       "3               Classification                        Real            3810   \n",
       "4               Classification        Categorical, Integer           48842   \n",
       "5               Classification               Real, Integer             900   \n",
       "6               Classification                        Real             569   \n",
       "7               Classification               Integer, Real             178   \n",
       "8   Classification, Regression                        Real            4898   \n",
       "9               Classification        Categorical, Integer               1   \n",
       "10              Classification                        Real             150   \n",
       "11              Classification               Integer, Real           13611   \n",
       "12              Classification  Categorical, Integer, Real             303   \n",
       "13              Classification                        Real            3810   \n",
       "14              Classification        Categorical, Integer           48842   \n",
       "15              Classification               Real, Integer             900   \n",
       "16              Classification                        Real             569   \n",
       "17              Classification               Integer, Real             178   \n",
       "18  Classification, Regression                        Real            4898   \n",
       "19              Classification        Categorical, Integer               1   \n",
       "\n",
       "   No of Attributes  Year   \n",
       "0                  4  Dona  \n",
       "1                 16  Dona  \n",
       "2                 13  Dona  \n",
       "3                  7  Dona  \n",
       "4                 14  Dona  \n",
       "5                  7  Dona  \n",
       "6                 30  Dona  \n",
       "7                 13  Dona  \n",
       "8                 11  Dona  \n",
       "9                 20     -  \n",
       "10                 4  Dona  \n",
       "11                16  Dona  \n",
       "12                13  Dona  \n",
       "13                 7  Dona  \n",
       "14                14  Dona  \n",
       "15                 7  Dona  \n",
       "16                30  Dona  \n",
       "17                13  Dona  \n",
       "18                11  Dona  \n",
       "19                20     -  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "Machine_learning = pd.DataFrame({})\n",
    "Machine_learning['Data Name'] = Dataset_name \n",
    "Machine_learning['Data Type '] = Data_type\n",
    "Machine_learning['Task '] = Task \n",
    "Machine_learning['Attribute Type '] = Attribute_type \n",
    "Machine_learning['No of Instance '] = No_of_instances\n",
    "Machine_learning['No of Attributes '] = No_of_attributes \n",
    "Machine_learning['Year '] = Year \n",
    "Machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "671c4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da7b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
